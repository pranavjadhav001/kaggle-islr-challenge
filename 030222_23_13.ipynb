{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    left_ROWS_per_frame = 21\n",
    "    sequence_length = 600\n",
    "    batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData(tf.keras.utils.Sequence):\n",
    "    def __init__(self,df_path,num_frames=20,batch_size=8,shuffle=True,\\\n",
    "                 labels_path='sign_to_prediction_index_map.json'):\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_frames = num_frames\n",
    "        self.labels  = json.load(open('sign_to_prediction_index_map.json','r'))\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.df))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        batches = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        left_hand_input = np.zeros(shape=(self.batch_size,self.num_frames,CFG.left_ROWS_per_frame,3))\n",
    "        right_hand_input = np.zeros(shape=(self.batch_size,self.num_frames,CFG.left_ROWS_per_frame,3))\n",
    "        labels = []\n",
    "        for i,row_val in enumerate(batches):\n",
    "            row = self.df.iloc[row_val]\n",
    "            left_hand,right_hand = self.load_video(row['path'])\n",
    "            left_hand_input[i,:] = left_hand\n",
    "            right_hand_input[i,:] = right_hand\n",
    "            labels.append(self.labels[row['sign']])\n",
    "        return [left_hand_input,right_hand_input],np.asarray(labels)\n",
    "            \n",
    "    def load_video(self,video_path):\n",
    "        video_df = pd.read_parquet(video_path, engine='pyarrow')\n",
    "        video_df.fillna(0,inplace=True)\n",
    "        left_df = video_df[video_df.type=='left_hand']\n",
    "        left_values = left_df[['x','y','z']].values\n",
    "        left_hand_array = np.zeros(shape=(600*CFG.left_ROWS_per_frame,3),dtype=np.float32)\n",
    "        left_hand_array[-len(left_values):] = left_values\n",
    "        left_hand_array = left_hand_array.reshape(600,CFG.left_ROWS_per_frame,3)\n",
    "        right_df = video_df[video_df.type=='right_hand']\n",
    "        right_values = right_df[['x','y','z']].values\n",
    "        right_hand_array = np.zeros(shape=(600*CFG.left_ROWS_per_frame,3),dtype=np.float32)\n",
    "        right_hand_array[-len(right_values):] = right_values\n",
    "        right_hand_array = right_hand_array.reshape(600,CFG.left_ROWS_per_frame,3)\n",
    "        return left_hand_array, right_hand_array\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)//self.batch_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = CustomData('train.csv',num_frames=600,batch_size=CFG.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d_lstm_block(inputs, filters):\n",
    "    vector = tf.keras.layers.ConvLSTM1D(filters=32, kernel_size=3)(inputs)\n",
    "    #for f in filters:\n",
    "    #    vector = tf.keras.layers.Conv1D(filters=f, kernel_size=8)(vector)\n",
    "    #    vector = tf.keras.layers.MaxPooling1D()(vector)\n",
    "    vector = tf.keras.layers.Dropout(0.3)(vector)\n",
    "    return vector\n",
    "\n",
    "def get_model():\n",
    "    input1 = tf.keras.Input((CFG.sequence_length, CFG.left_ROWS_per_frame, 3), dtype=tf.float32)\n",
    "    input2 = tf.keras.Input((CFG.sequence_length, CFG.left_ROWS_per_frame, 3), dtype=tf.float32)\n",
    "    left_hand_vector = conv1d_lstm_block(input1, [64])\n",
    "    right_hand_vector = conv1d_lstm_block(input2, [64])\n",
    "    vector = tf.keras.layers.Concatenate(axis=1)([left_hand_vector, right_hand_vector])\n",
    "    vector = tf.keras.layers.Flatten()(vector)\n",
    "    output = tf.keras.layers.Dense(250, activation=\"softmax\")(vector)\n",
    "    model = tf.keras.Model(inputs=[input1,input2], outputs=output)\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\n",
    "            \"accuracy\",\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 600, 21, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 600, 21, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv_lstm1d (ConvLSTM1D)       (None, 19, 32)       13568       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv_lstm1d_1 (ConvLSTM1D)     (None, 19, 32)       13568       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 19, 32)       0           ['conv_lstm1d[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 19, 32)       0           ['conv_lstm1d_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38, 32)       0           ['dropout[0][0]',                \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1216)         0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 250)          304250      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 331,386\n",
      "Trainable params: 331,386\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1286/2952 [============>.................] - ETA: 40:30 - loss: 5.4065 - accuracy: 0.0153"
     ]
    }
   ],
   "source": [
    "file_name = \"model.h5\"\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        file_name, \n",
    "        save_best_only=True, \n",
    "        restore_best_weights=True, \n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\"\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5, \n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\"\n",
    "    )\n",
    "]\n",
    "model.fit(datagen, epochs=30, callbacks=callbacks)\n",
    "model = tf.keras.models.load_model(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = datagen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
